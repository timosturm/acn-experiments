{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:19:49.648086500Z",
     "start_time": "2024-11-19T13:19:49.593398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| os.getpid(): 263055\n"
     ]
    },
    {
     "data": {
      "text/plain": "263055"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is importent when we want to call this as a python script, because jupyter naturally has a higher recursion depth\n",
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "# Print the PID when using nohup\n",
    "import os\n",
    "from icecream import ic\n",
    "ic(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:19:58.550100500Z",
     "start_time": "2024-11-19T13:19:53.810797400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| train_generator.end_date + timedelta(days=1): datetime.datetime(2019, 1, 9, 0, 0, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>)\n",
      "ic| eval_generator.end_date + timedelta(days=1): datetime.datetime(2019, 1, 17, 0, 0, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>)\n",
      "ic| validation_generator.end_date + timedelta(days=1): datetime.datetime(2019, 2, 1, 0, 0, tzinfo=<DstTzInfo 'America/Los_Angeles' PST-1 day, 16:00:00 STD>)\n"
     ]
    }
   ],
   "source": [
    "from gymportal.data.ev_generators import get_standard_generator, RealWorldGenerator\n",
    "from acnportal.acnsim import Linear2StageBattery\n",
    "from gymportal.data.battery_generators import CustomizableBatteryGenerator\n",
    "from gymportal.sim import get_charging_network, Recomputer, EvaluationSimulator, SimGenerator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pytz\n",
    "timezone = pytz.timezone(\"America/Los_Angeles\")\n",
    "\n",
    "\n",
    "# charging_network = get_charging_network('simple_acn', basic_evse=True, voltage=208,\n",
    "#                                         network_kwargs={\n",
    "#                                             'station_ids': ['CA-504', 'CA-503', 'CA-502', 'CA-501'],\n",
    "#                                              #'station_ids': ['CA-501'],\n",
    "# \"aggregate_cap\": 32 * 208 / 1000})\n",
    "\n",
    "charging_network = get_charging_network('caltech', basic_evse=True, voltage=208,\n",
    "                                        network_kwargs={\"transformer_cap\": 150})\n",
    "\n",
    "battery_generator = CustomizableBatteryGenerator(\n",
    "    voltage=208,\n",
    "    period=1,\n",
    "    battery_types=[\n",
    "        Linear2StageBattery],\n",
    "    max_power_function=\"normal\",\n",
    ")\n",
    "\n",
    "ev_generator = RealWorldGenerator(battery_generator=battery_generator, site='caltech', period=1)\n",
    "# ev_generator = get_standard_generator(\n",
    "#     'caltech', battery_generator, seed=42, frequency_multiplicator=frequency_multiplicator, duration_multiplicator=2)\n",
    "\n",
    "train_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=7,\n",
    "    n_intervals=1,\n",
    "    start_date=timezone.localize(datetime(2019, 1, 1)),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(train_generator.end_date + timedelta(days=1))\n",
    "\n",
    "eval_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=7,\n",
    "    n_intervals=1,\n",
    "    start_date=train_generator.end_date + timedelta(days=1),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(eval_generator.end_date + timedelta(days=1))\n",
    "\n",
    "validation_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=14,\n",
    "    n_intervals=1,\n",
    "    start_date=eval_generator.end_date + timedelta(days=1),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(validation_generator.end_date + timedelta(days=1))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:20:04.266017200Z",
     "start_time": "2024-11-19T13:20:02.286008300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                   P           G(i)          H_sun            T2m  \\\ncount  140256.000000  140256.000000  140256.000000  140256.000000   \nmean    30395.798319     267.983145      16.748906      17.931872   \nstd     40648.543625     356.157287      22.166668       7.394042   \nmin         0.000000       0.000000      -5.880000      -2.230000   \n25%         0.000000       0.000000       0.000000      12.360000   \n50%        87.000000       7.260000       0.520000      17.310000   \n75%     65764.500000     564.280000      31.982500      23.010000   \nmax    132601.500000    1143.220000      78.090000      46.460000   \n\n               WS10m       Int  \ncount  140256.000000  140256.0  \nmean        1.654366       0.0  \nstd         0.867817       0.0  \nmin         0.000000       0.0  \n25%         0.970000       0.0  \n50%         1.590000       0.0  \n75%         2.280000       0.0  \nmax         7.930000       0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P</th>\n      <th>G(i)</th>\n      <th>H_sun</th>\n      <th>T2m</th>\n      <th>WS10m</th>\n      <th>Int</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>140256.000000</td>\n      <td>140256.000000</td>\n      <td>140256.000000</td>\n      <td>140256.000000</td>\n      <td>140256.000000</td>\n      <td>140256.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>30395.798319</td>\n      <td>267.983145</td>\n      <td>16.748906</td>\n      <td>17.931872</td>\n      <td>1.654366</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>40648.543625</td>\n      <td>356.157287</td>\n      <td>22.166668</td>\n      <td>7.394042</td>\n      <td>0.867817</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-5.880000</td>\n      <td>-2.230000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.360000</td>\n      <td>0.970000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>87.000000</td>\n      <td>7.260000</td>\n      <td>0.520000</td>\n      <td>17.310000</td>\n      <td>1.590000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>65764.500000</td>\n      <td>564.280000</td>\n      <td>31.982500</td>\n      <td>23.010000</td>\n      <td>2.280000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>132601.500000</td>\n      <td>1143.220000</td>\n      <td>78.090000</td>\n      <td>46.460000</td>\n      <td>7.930000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pv.pv import read_pv_data\n",
    "\n",
    "df_pv = read_pv_data(\"pv_time.csv\")\n",
    "df_pv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from gymportal.environment import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-19T13:20:04.374736300Z",
     "start_time": "2024-11-19T13:20:04.276357900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:05:00.374950100Z",
     "start_time": "2024-11-19T13:05:00.304930500Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.run_simulation import metrics\n",
    "from gymportal.environment import *\n",
    "from src.extra import unplug_penalty\n",
    "from src.pv.metrics import pv_utilization_mean\n",
    "from src.pv.observations import pv_observation_mean\n",
    "from src.pv.rewards import pv_utilization\n",
    "import numpy as np\n",
    "from src.pv.utils import pv_to_A\n",
    "from src.pv.pv import most_recent_P\n",
    "from acnportal.acnsim import Simulator\n",
    "\n",
    "\n",
    "def soft_charging_reward() -> SimReward:\n",
    "    \"\"\"\n",
    "    Rewards for charge delivered in the last timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def multi_reward(env: BaseSimInterface) -> MultiAgentDict:\n",
    "        charging_rates = env.interface.charging_rates\n",
    "\n",
    "        timestep = env.timestep\n",
    "        prev_timestep = env.prev_timestep\n",
    "\n",
    "        soft_reward = {\n",
    "            station_id: 0 for station_id in env.interface.station_ids}\n",
    "\n",
    "        for idx, station_id in enumerate(env.interface.station_ids):\n",
    "            soft_reward[station_id] = np.sum(\n",
    "                charging_rates[idx, prev_timestep: timestep]) / (env.interface.max_pilot_signal(station_id) * (\n",
    "                    timestep - prev_timestep))\n",
    "\n",
    "        return soft_reward\n",
    "\n",
    "    def single_reward(env: BaseSimInterface) -> float:\n",
    "        multi_dict = multi_reward(env)\n",
    "\n",
    "        return float(np.sum(list(multi_dict.values()))) / len(multi_dict.keys())\n",
    "\n",
    "    return SimReward(single_reward_function=single_reward,\n",
    "                     multi_reward_function=multi_reward, name=\"soft_charging_reward\")\n",
    "\n",
    "\n",
    "\n",
    "def soft_charging_reward_pv_weighted(df_pv, transformer_cap) -> SimReward:\n",
    "    \"\"\"\n",
    "    Rewards for charge delivered in the last timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def multi_reward(env: BaseSimInterface) -> MultiAgentDict:\n",
    "        charging_rates = env.interface.charging_rates\n",
    "\n",
    "        timestep = env.timestep\n",
    "        prev_timestep = env.prev_timestep\n",
    "\n",
    "        soft_reward = {\n",
    "            station_id: 0 for station_id in env.interface.station_ids}\n",
    "\n",
    "        for idx, station_id in enumerate(env.interface.station_ids):\n",
    "            soft_reward[station_id] = np.sum(\n",
    "                charging_rates[idx, prev_timestep: timestep]) / (env.interface.max_pilot_signal(station_id) * (\n",
    "                    timestep - prev_timestep))\n",
    "\n",
    "        return soft_reward\n",
    "\n",
    "    def single_reward(env: BaseSimInterface) -> float:        \n",
    "        timestep_now = env.timestep\n",
    "        timestep_prev = env.prev_timestep\n",
    "        sim: Simulator = env.interface._simulator\n",
    "\n",
    "        timesteps = np.array(\n",
    "            list(\n",
    "                range(timestep_prev, timestep_now, sim.period)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        timesteps_as_dt = [\n",
    "            env.interface.timestep_to_datetime(t) for t in timesteps\n",
    "        ]\n",
    "        \n",
    "        pvs_in_W = np.array(\n",
    "            [most_recent_P(df_pv, dt) for dt in timesteps_as_dt]\n",
    "        )\n",
    "        \n",
    "        ratio = pvs_in_W / transformer_cap\n",
    "        \n",
    "        charging_rates = env.interface.charging_rates\n",
    "        charging_rates[:, timestep_prev: timestep_now]\n",
    "        return ratio * np.sum(charging_rates[:, timestep_prev: timestep_now], axis=0) # assert shape ==(10,)\n",
    "        \n",
    "\n",
    "        # pvs_in_A = [pv_to_A(x, sim.network._voltages) for x in pvs_in_W]\n",
    "        \n",
    "\n",
    "    return SimReward(single_reward_function=single_reward,\n",
    "                     multi_reward_function=multi_reward, name=\"soft_charging_reward_pv_weighted\")\n",
    "\n",
    "\n",
    "observation_objects = [\n",
    "    charging_rates_observation_normalized(),\n",
    "    percentage_of_magnitude_observation(),\n",
    "    diff_pilots_charging_rates_observation_normalized(),\n",
    "    cyclical_minute_observation(),\n",
    "    cyclical_day_observation(),\n",
    "    cyclical_month_observation(),\n",
    "    cyclical_minute_observation_stay(),\n",
    "    energy_delivered_observation_normalized(),\n",
    "    num_active_stations_observation_normalized(),\n",
    "    pilot_signals_observation_normalized(),\n",
    "    cyclical_minute_observation_arrival(),\n",
    "    cyclical_day_observation_arrival(),\n",
    "    cyclical_month_observation_arrival(),\n",
    "    pv_observation_mean(df_pv),\n",
    "]\n",
    "\n",
    "reward_objects = [\n",
    "    # current_constraint_violation(),\n",
    "    soft_charging_reward_pv_weighted(df_pv, 150),\n",
    "    # constraint_charging_reward(),\n",
    "    # unplug_penalty(),\n",
    "    # pilot_charging_rate_difference_penalty(),\n",
    "    pv_utilization(df_pv),\n",
    "]\n",
    "\n",
    "metrics[\"pv_utilization_mean\"] = lambda sim: pv_utilization_mean(sim, df_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:05:02.314102700Z",
     "start_time": "2024-11-19T13:05:02.282828100Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.actions import ranking_schedule_plus, zero_centered_single_charging_schedule_normalized_clip\n",
    "\n",
    "train_config = {\"observation_objects\": observation_objects, \"action_object\": zero_centered_single_charging_schedule_normalized_clip(),\n",
    "                \"reward_objects\": reward_objects,\n",
    "                \"simgenerator\": train_generator,\n",
    "                \"meet_constraints\": True}\n",
    "\n",
    "eval_config = train_config | {'simgenerator': eval_generator}\n",
    "validation_config = train_config | {'simgenerator': validation_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:05:03.859127100Z",
     "start_time": "2024-11-19T13:05:03.837859200Z"
    }
   },
   "outputs": [],
   "source": [
    "# import dill as pickle\n",
    "# with open(\"caltech.pkl\",'rb') as file:\n",
    "#     env = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:08:49.917510800Z",
     "start_time": "2024-11-19T13:05:04.899385900Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils import FlattenSimEnv\n",
    "\n",
    "\n",
    "env = FlattenSimEnv(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T13:18:56.232459300Z",
     "start_time": "2024-11-19T13:15:37.968934200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| f\"preparing simulation {i}\": 'preparing simulation 0'\n"
     ]
    }
   ],
   "source": [
    "lengths_load = []\n",
    "\n",
    "for i in range(1):\n",
    "    ic(f\"preparing simulation {i}\")\n",
    "    env.reset()\n",
    "    length = len(env.interface._simulator.event_queue.queue)\n",
    "    lengths_load.append(length)\n",
    "    \n",
    "steps_per_epoch = np.sum(lengths_load) # look at all 46 weeks per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ppo_custom.ppo_model import PPO\n",
    "\n",
    "algo = PPO(env, max_episode_len=np.inf, steps_per_epoch=steps_per_epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymportal.evaluation import ACNSchedule, RllibSchedule\n",
    "from acnportal.algorithms import UncontrolledCharging, SortedSchedulingAlgo, last_come_first_served, \\\n",
    "    first_come_first_served\n",
    "from src.utils import CustomSchedule\n",
    "\n",
    "\n",
    "models = {\n",
    "    # \"PPO\": CustomSchedule(algo),\n",
    "    # \"FCFS\": ACNSchedule(SortedSchedulingAlgo(first_come_first_served)),\n",
    "    # \"LCFS\": ACNSchedule(SortedSchedulingAlgo(last_come_first_served)),\n",
    "    # \"Uncontrolled\": ACNSchedule(UncontrolledCharging()),\n",
    "}\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"ppo_x\", group=\"PV\", name=f\"soft_charging_weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.ppo_custom.callbacks import EvaluationMetricsCallback, EvaluationFigureCallback\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"all\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=6,\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[\n",
    "        EvaluationMetricsCallback(models, metrics, eval_config, seed=42, run=run),\n",
    "        ModelCheckpoint(save_top_k=-1, every_n_epochs=1,\n",
    "                        save_on_train_epoch_end=True),\n",
    "        EvaluationFigureCallback(charging_network, timezone, ev_generator, train_config, run=run),\n",
    "    ]\n",
    ")\n",
    "\n",
    "res = trainer.fit(algo)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"last_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
