{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is importent when we want to call this as a python script, because jupyter naturally has a higher recursion depth\n",
    "import sys\n",
    "sys.setrecursionlimit(3000)\n",
    "\n",
    "# Print the PID when using nohup\n",
    "import os\n",
    "from icecream import ic\n",
    "ic(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymportal.data.ev_generators import get_standard_generator, RealWorldGenerator\n",
    "from acnportal.acnsim import Linear2StageBattery\n",
    "from gymportal.data.battery_generators import CustomizableBatteryGenerator\n",
    "from gymportal.sim import get_charging_network, Recomputer, EvaluationSimulator, SimGenerator\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pytz\n",
    "timezone = pytz.timezone(\"America/Los_Angeles\")\n",
    "\n",
    "\n",
    "# charging_network = get_charging_network('simple_acn', basic_evse=True, voltage=208,\n",
    "#                                         network_kwargs={\n",
    "#                                             'station_ids': ['CA-504', 'CA-503', 'CA-502', 'CA-501'],\n",
    "#                                              #'station_ids': ['CA-501'],\n",
    "# \"aggregate_cap\": 32 * 208 / 1000})\n",
    "\n",
    "charging_network = get_charging_network('caltech', basic_evse=True, voltage=208,\n",
    "                                        network_kwargs={\"transformer_cap\": 150})\n",
    "\n",
    "battery_generator = CustomizableBatteryGenerator(\n",
    "    voltage=208,\n",
    "    period=1,\n",
    "    battery_types=[\n",
    "        Linear2StageBattery],\n",
    "    max_power_function=\"normal\",\n",
    ")\n",
    "\n",
    "ev_generator = RealWorldGenerator(battery_generator=battery_generator, site='caltech', period=1)\n",
    "# ev_generator = get_standard_generator(\n",
    "#     'caltech', battery_generator, seed=42, frequency_multiplicator=frequency_multiplicator, duration_multiplicator=2)\n",
    "\n",
    "train_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=7,\n",
    "    n_intervals=46,\n",
    "    start_date=timezone.localize(datetime(2019, 1, 1)),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(train_generator.end_date + timedelta(days=1))\n",
    "\n",
    "eval_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=7,\n",
    "    n_intervals=1,\n",
    "    start_date=train_generator.end_date + timedelta(days=1),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(eval_generator.end_date + timedelta(days=1))\n",
    "\n",
    "validation_generator = SimGenerator(\n",
    "    charging_network=charging_network,\n",
    "    simulation_days=14,\n",
    "    n_intervals=1,\n",
    "    start_date=eval_generator.end_date + timedelta(days=1),\n",
    "    ev_generator=ev_generator,\n",
    "    recomputer=Recomputer(recompute_interval=10, sparse=True),\n",
    "    sim_class=EvaluationSimulator,\n",
    ")\n",
    "\n",
    "ic(validation_generator.end_date + timedelta(days=1))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pv.pv import read_pv_data\n",
    "\n",
    "df_pv = read_pv_data(\"pv_time.csv\")\n",
    "df_pv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.run_simulation import metrics\n",
    "from gymportal.environment import *\n",
    "from src.extra import unplug_penalty\n",
    "from src.pv.metrics import pv_utilization_mean\n",
    "from src.pv.observations import pv_observation_mean\n",
    "from src.pv.rewards import pv_utilization\n",
    "\n",
    "\n",
    "def soft_charging_reward() -> SimReward:\n",
    "    \"\"\"\n",
    "    Rewards for charge delivered in the last timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def multi_reward(env: BaseSimInterface) -> MultiAgentDict:\n",
    "        charging_rates = env.interface.charging_rates\n",
    "\n",
    "        timestep = env.timestep\n",
    "        prev_timestep = env.prev_timestep\n",
    "\n",
    "        soft_reward = {\n",
    "            station_id: 0 for station_id in env.interface.station_ids}\n",
    "\n",
    "        for idx, station_id in enumerate(env.interface.station_ids):\n",
    "            soft_reward[station_id] = np.sum(\n",
    "                charging_rates[idx, prev_timestep: timestep]) / (env.interface.max_pilot_signal(station_id) * (\n",
    "                    timestep - prev_timestep))\n",
    "\n",
    "        return soft_reward\n",
    "\n",
    "    def single_reward(env: BaseSimInterface) -> float:\n",
    "        multi_dict = multi_reward(env)\n",
    "\n",
    "        return float(np.sum(list(multi_dict.values()))) / len(multi_dict.keys())\n",
    "\n",
    "    return SimReward(single_reward_function=single_reward,\n",
    "                     multi_reward_function=multi_reward, name=\"soft_charging_reward\")\n",
    "\n",
    "\n",
    "observation_objects = [\n",
    "    charging_rates_observation_normalized(),\n",
    "    percentage_of_magnitude_observation(),\n",
    "    diff_pilots_charging_rates_observation_normalized(),\n",
    "    cyclical_minute_observation(),\n",
    "    cyclical_day_observation(),\n",
    "    cyclical_month_observation(),\n",
    "    cyclical_minute_observation_stay(),\n",
    "    energy_delivered_observation_normalized(),\n",
    "    num_active_stations_observation_normalized(),\n",
    "    pilot_signals_observation_normalized(),\n",
    "    cyclical_minute_observation_arrival(),\n",
    "    cyclical_day_observation_arrival(),\n",
    "    cyclical_month_observation_arrival(),\n",
    "    pv_observation_mean(df_pv),\n",
    "]\n",
    "\n",
    "reward_objects = [\n",
    "    # current_constraint_violation(),\n",
    "    # soft_charging_reward(),\n",
    "    # constraint_charging_reward(),\n",
    "    # unplug_penalty(),\n",
    "    # pilot_charging_rate_difference_penalty(),\n",
    "    pv_utilization(df_pv),\n",
    "]\n",
    "\n",
    "metrics[\"pv_utilization_mean\"] = lambda sim: pv_utilization_mean(sim, df_pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.actions import ranking_schedule, ranking_schedule_plus, zero_centered_single_charging_schedule_normalized_clip\n",
    "\n",
    "train_config = {\"observation_objects\": observation_objects, \"action_object\": ranking_schedule(),\n",
    "                \"reward_objects\": reward_objects,\n",
    "                \"simgenerator\": train_generator,\n",
    "                \"meet_constraints\": True}\n",
    "\n",
    "eval_config = train_config | {'simgenerator': eval_generator}\n",
    "validation_config = train_config | {'simgenerator': validation_generator}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dill as pickle\n",
    "# with open(\"caltech.pkl\",'rb') as file:\n",
    "#     env = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import FlattenSimEnv\n",
    "\n",
    "\n",
    "env = FlattenSimEnv(train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths_load = []\n",
    "\n",
    "for i in range(46):\n",
    "    ic(f\"preparing simulation {i}\")\n",
    "    env.reset()\n",
    "    length = len(env.interface._simulator.event_queue.queue)\n",
    "    lengths_load.append(length)\n",
    "    \n",
    "steps_per_epoch = np.sum(lengths_load) # look at all 46 weeks per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ppo_custom.ppo_model import PPO\n",
    "\n",
    "algo = PPO(env, max_episode_len=np.inf, steps_per_epoch=steps_per_epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymportal.evaluation import ACNSchedule, RllibSchedule\n",
    "from acnportal.algorithms import UncontrolledCharging, SortedSchedulingAlgo, last_come_first_served, \\\n",
    "    first_come_first_served\n",
    "from src.utils import CustomSchedule\n",
    "\n",
    "\n",
    "models = {\n",
    "    # \"PPO\": CustomSchedule(algo),\n",
    "    # \"FCFS\": ACNSchedule(SortedSchedulingAlgo(first_come_first_served)),\n",
    "    # \"LCFS\": ACNSchedule(SortedSchedulingAlgo(last_come_first_served)),\n",
    "    # \"Uncontrolled\": ACNSchedule(UncontrolledCharging()),\n",
    "}\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init(project=\"ppo_x\", group=\"PV\", name=f\"ranking_util_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from src.ppo_custom.callbacks import EvaluationMetricsCallback, EvaluationFigureCallback\n",
    "\n",
    "wandb_logger = WandbLogger(log_model=\"all\")\n",
    "trainer = Trainer(\n",
    "    max_epochs=6,\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"cpu\",\n",
    "    callbacks=[\n",
    "        EvaluationMetricsCallback(models, metrics, eval_config, seed=42, run=run),\n",
    "        ModelCheckpoint(save_top_k=-1, every_n_epochs=1,\n",
    "                        save_on_train_epoch_end=True),\n",
    "        EvaluationFigureCallback(charging_network, timezone, ev_generator, train_config, run=run),\n",
    "    ]\n",
    ")\n",
    "\n",
    "res = trainer.fit(algo)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"last_checkpoint.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
